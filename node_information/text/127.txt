   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires La Quadrature du Net » Reconnaissance faciale : un recours
   pour faire barrage à la surveillance biométrique Flux des commentaires
   [ActualitedesLuttes] Vidéosurveillance et menace des libertés sur les
   réseaux sociaux Le Conseil constitutionnel censure l’accès des douanes
   aux données de connexion alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

Reconnaissance faciale : un recours pour faire barrage à la surveillance
biométrique

   Posted on19 février 201919 février 2019

   Quatre organisations – La Quadrature du Net, la Ligue des droits de
   l’Homme, CGT Educ’Action des Alpes-Maritimes et la Fédération des
   Conseils de Parents d’Élèves des écoles publiques des Alpes-Maritimes –
   viennent de déposer un recours devant le tribunal administratif de
   Marseille pour demander l’annulation de la délibération du conseil
   régional autorisant la mise en œuvre d’une expérimentation de
   reconnaissance faciale dans deux lycées de la région.

   Ce recours intervient alors que la polémique enfle après que la mairie
   de Nice a annoncé expérimenter la reconnaissance faciale dans le cadre
   du carnaval.

   Le 14 décembre 2018, le conseil régional de la région Sud (ex-PACA) a
   voté une délibération visant à faire installer à l’entrée de deux
   lycées de la région — le lycée des Eucalyptus à Nice et le lycée Ampère
   à Marseille — un dispositif de reconnaissance faciale. Ce dispositif
   expérimental, installé et financé par la société états-unienne Cisco, a
   vocation, comme l’a précisé M. Christian Estrosi lors du vote au
   Conseil régional, à être étendu à l’ensemble des établissements
   scolaires de la région.

   Devant l’inaction de la CNIL et alors que cette expérimentation prépare
   la banalisation de la surveillance par reconnaissance faciale, les
   quatre organisations requérantes ont décidé de saisir le tribunal
   administratif de Marseille pour demander l’annulation de cette
   délibération.

   Les arguments juridiques soulevés s’appuient essentiellement sur le
   règlement général sur la protection des données (RGPD) : la
   délibération, votée alors qu’aucune analyse d’impact n’avait été
   réalisée, permet en effet la mise en œuvre d’un traitement de données
   biométriques qui est notamment manifestement disproportionné par
   rapport à l’objectif poursuivi (apporter « une assistance aux agents en
   charge du contrôle d’accès au lycée et de l’accueil ») et qui n’est
   fondée sur aucune règle juridique adaptée, claire et intelligible,
   contrairement à ce qu’impose la Convention européenne des droits de
   l’Homme en matière de droit à la vie privée. La délibération autorisant
   cette expérimentation est donc illégale et doit être annulée.

   Le recours est accessible ici.

   Pour Martin Drago, juriste à La Quadrature du Net :

   « Cette expérimentation vise à accoutumer les élèves à une surveillance
   biométrique. Cela participe à la banalisation de ce type de
   technologies, alors que des projets sécuritaires de vidéosurveillance
   dopées à la reconnaissance faciale pullulent désormais sur le
   territoire français. On trouve malheureusement bien peu de monde pour y
   faire barrage, que ce soit à la CNIL ou au niveau des élus locaux et à
   ce stade, les juges apparaissent comme l’ultime rempart
   institutionnel. »

   Pour Maryse Artiguelong, vice-présidente de la Ligue des droits de
   l’Homme :

   « Pour la Ligue des droits de l’Homme (LDH) cette expérimentation de
   reconnaissance faciale, qui permet l’identification à l’aide de données
   biométriques particulièrement sensibles – elles permettent notamment de
   déterminer l’origine ethnique, qui plus est sur des élèves en majorité
   mineurs – est particulièrement inquiétante. »

   Pour Laure Guérard-Boushor, de la CGT Educ’Action des Alpes-Maritimes :

   « Répression contre les lycéen.ne.s, mise en place de mesures pour
   restreindre le droit de manifester et maintenant mise en place d’un
   système de reconnaissance faciale à l’entrée de l’établissement les EK
   à Nice et Ampère à Marseille; l’escalade est toujours plus importante.
   Nous condamnons ces projets qui remettent en cause tous les principes
   de la liberté qu’elle soit individuelle ou collective ; qui laissent la
   porte ouverte à toutes les dérives, toutes les discriminations. Nous
   demandons à ce que l’argent dont notre école publique a besoin ne soit
   pas gaspillé dans des mesures dont on connaît l’inutilité et la
   nocivité. »

   Pour Laëtitia Siccardi, présidente de la Fédération des Conseils de
   Parents d’Élèves des écoles publiques des Alpes-Maritimes :

   « Cette expérimentation est une dérive sécuritaire de plus, et nous
   sommes extrêmement attentifs à ce que les droits fondamentaux des
   lycéens soient respectés. De plus, il s’agit une fois encore d’un
   investissement financier considérable au service d’une mesure à
   l’efficacité douteuse.»

   Posted in Surveillance
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires La Quadrature du Net » Reconnaissance faciale au lycée :
   l’expérimentation avant la généralisation Flux des commentaires Résumé
   de nos arguments contre la surveillance française devant les juges
   européens Première sanction contre Google suite à nos plaintes
   collectives alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

Reconnaissance faciale au lycée : l’expérimentation avant la généralisation

   Posted on19 décembre 201820 décembre 2018

   Le 14 décembre dernier, le Conseil Régional de PACA a voté une mesure
   visant à faire installer, à partir de 2019, des dispositifs de
   reconnaissance faciale à l’entrée de deux lycées de Nice et de
   Marseille. Dès le mois d’octobre, La Quadrature du Net avait demandé à
   la CNIL la communication des documents en sa possession sur ce dossier,
   cette dernière ayant été consultée par la région pour la mise en place
   de ces dispositifs. L’analyse de ces documents, ainsi que les
   précisions apportées par Christian Estrosi, confirment l’impuissance de
   la CNIL à enrayer la banalisation d’une technologie particulièrement
   liberticide et qui vise ici à s’étendre à l’ensemble des établissements
   scolaires de la région.

   Mise à jour (20 décembre 2018) – nous publions les documents suivants :
     * La réponse de la CNIL à notre demande
     * La lettre de Renaud Muselier présentant le projet à la CNIL
     * L’exposé détaillé du projet par la région
     * La demande de renseignements complémentaires par la CNIL à la
       région et la réponse de cette dernière

   De quoi s’agit-il ? En octobre 2017, Renaud Muselier, président de la
   région PACA, demande les conseils de la CNIL pour la mise en place dans
   deux lycées de Nice et de Marseille de dispositifs de « portiques
   virtuels » associant « des moyens classiques d’identification (…) à un
   dispositif biométrique utilisant des technologies de comparaison
   faciale, seuls à même d’après nos premières investigations, d’apporter
   une solution fiable et rapide dans un contexte de contrôle d’accès
   portant sur un nombre potentiellement élevé de personnes ». Cette
   nouvelle étape est la suite logique de sa politique sécuritaire ayant
   conduit, entre 2016 et 2017, à ce que plus de 1 300 caméras de
   vidéosurveillance soient installées dans l’ensemble des lycées de la
   région. La technologisation à outrance est également présentée par la
   région comme une réponse au contexte d’austérité budgétaire :

     Ce dispositif constitue une réponse au différentiel croissant
     constaté entre les exigences de sécurisation des entrées dans les
     établissements et les moyens humains disponibles dans les lycées,
     dans le cadre des plans successifs de réduction des effectifs dans
     la fonction publique.

   La région PACA présente ainsi à la CNIL son projet visant à
   « sanctuariser » les entrées et les sorties dans les établissements
   secondaires. Il s’agit non seulement de reconnaissance faciale mais
   également d’un dispositif de « suivi de trajectoire » de certains des
   visiteurs : un logiciel installé couplé à une caméra permet de détecter
   des points de comparaison faciale déterminés par un algorithme et de le
   comparer avec ceux stockés dans une base de données. Un écran mis à la
   disposition des agents de contrôle permet alors de visualiser trois
   types de profils : « vert » pour les personnes autorisées à pénétrer
   dans l’enceinte du lycée, « jaune » pour les personnes non identifiées
   et invitées à se présenter à l’accueil et « rouge » pour les personnes
   non identifiées et qui ne se sont pas dirigées dès leur entrée vers
   l’accueil.

   Il est par ailleurs précisé qu’il s’agit pour l’instant d’une
   « expérimentation limitée dans le temps » et fondée sur le consentement
   explicite de volontaires au sein des établissements visés.

La CNIL impuissante face au développement de la reconnaissance faciale

   Alors qu’elle avait appelé en septembre 2018 à un débat urgent sur ces
   nouveaux usages des caméras vidéo et qu’elle souligne elle-même les
   risques considérables d’atteinte aux libertés individuelles que cette
   technologie entraîne, la CNIL n’a opéré ici qu’un suivi très souple –
   voire accommodant – du projet.

   Soulignons d’abord que, depuis l’entrée en vigueur du RGPD en mai 2018,
   les responsables de traitement de données personnelles n’ont en
   principe plus à réaliser de formalités auprès de la CNIL avant la mise
   en œuvre du traitement, tel qu’obtenir son autorisation dans certains
   cas. Le contrôle de l’autorité ne se fait qu’a posteriori, conformément
   au principe de responsabilisation des acteurs prévu dans le règlement.
   Tout au plus certains traitements, et c’est le cas pour la
   reconnaissance faciale, doivent-ils faire l’objet d’une analyse
   d’impact. Le consentement des utilisateurs est désormais censé fournir
   une base légale suffisante pour le déploiement de ces systèmes qui font
   pourtant entrer la surveillance dans une nouvelle ère. En supprimant le
   pouvoir d’autorisation de la CNIL s’agissant de ce type de dispositifs,
   le RGPD marque donc un recul pour les libertés.

   Selon les documents qui nous ont été communiqués, la CNIL s’est donc
   contentée de demander des précisions complémentaires à la Région sur le
   dispositif envisagé et, sur certains points, de fournir des
   recommandations. C’est d’ailleurs suite à l’une de ces recommandations
   que la Région a décidé que le stockage des données biométriques ne se
   ferait pas sur une base de données mais sur un support individuel, sous
   le contrôle exclusif de la personne (en l’espèce, un badge) (comme
   c’est le cas pour ce qui existe déjà dans plusieurs aéroports où la
   photographie n’est stockée que dans le microprocesseur du passeport
   biométrique).

   Ainsi, et contrairement à ce qui a été annoncé par une partie de la
   presse et par Christian Estrosi lui-même, la CNIL n’a pas donné son
   « feu vert » à ce dispositif mais a simplement accompagné la région
   dans sa mise en place.

   Pourtant, en laissant se développer ce type de technologies à des buts
   sécuritaires, sans qu’il ne soit apporté à un seul moment la preuve de
   la pertinence d’un tel dispositif par rapport au système existant,^1Il
   est ainsi seulement précisé dans les documents produits par la région,
   et cela sans aucune preuve ou réelle analyse, que « les nombreux
   incidents et agressions constatés aussi bien dans l’enceinte du lycée
   qu’à ses abords, ainsi que le contexte sécuritaire existant depuis les
   attentats terroristes de 2016, conduisent également à tenter de limiter
   les temps d’attente et les attroupements à l’extérieur des
   établissements aux moments de forte affluence (rentrées matinales
   notamment) » ou que « ce dispositif constitue une réponse au
   différentiel croissant constaté entre les exigences de sécurisation des
   entrées dans les établissements et les moyens humains disponibles dans
   les lycées, dans le cadre des plans successifs de réduction des
   effectifs de la fonction publique. Il apporte une assistance aux
   personnels du lycée, qui peuvent ainsi mieux se concentrer sur les cas
   nécessitant une intervention humaine, et reporter leur vigilance sur
   les multiples situations menaçant la sécurité, en augmentant la
   présence humaine dans les lieux de vie de l’établissement. » sans même
   une réelle réflexion sur la nature du consentement que peuvent donner
   des mineurs à l’égard d’une expérimentation au sein de leur lycée,^2Le
   courrier de la région précise à ce titre que « Les personnes
   volontaires (ou leur représentant légal pour les mineurs) doivent
   signer préalablement un formulaire de recueil de consentement
   expliquant la finalité de l’expérimentation, la durée de conservation
   des donnée ainsi que la manière d’exercer les droits Informatique et
   Libertés » la CNIL participe à la banalisation de ces technologies.
   Elle devient l’alibi au développement d’une surveillance généralisée
   qui sera au cœur des « Safe City » qui commencent à essaimer sur le
   territoire.

Un dispositif qui a vocation à s’étendre à toute la région

   Car, sous le qualificatif faussement tranquillisant d’
   « expérimentation » mis en exergue par Renaud Muselier et Christian
   Estrosi, ces derniers souhaitent en réalité, comme ils l’ont eux-mêmes
   énoncé lors de l’assemblée plénière du Conseil Régional, étendre ce
   dispositif de reconnaissance faciale à l’ensemble des lycées de la
   région :

     Avec ces deux expériences, une fois que nous l’aurons démontré, nous
     irons très vite sur la généralisation, à partir du réseau de
     vidéosurveillance déjà existant, sur lequel il ne nous restera plus
     qu’à mettre le logiciel qui correspond à l’usage de la
     reconnaissance faciale par rapport aux caméras déjà installées dans
     nos établissements scolaires.

   L’expérimentation des lycées de Nice et de Marseille s’inscrit donc en
   réalité parfaitement dans les divers projets que La Quadrature du Net
   dénonce depuis près d’un an, et qui sont d’ailleurs particulièrement
   avancés dans ces deux villes : « Observatoire Big Data de la
   tranquillité publique » à Marseille, « Safe City » à Nice… Cette
   actualité apparaît alors comme une
   nouvelle briqueau développement, toujours plus rapide et incontrôlable,
   de ces nouvelles technologies de surveillance (« Big Data », caméras
   « intelligentes », reconnaissance faciale…) au profit des municipalités
   et de leurs polices.

   Un tel projet profitera par ailleurs pleinement à son maître d’œuvre,
   la société CISCO, qui finance entièrement cette expérimentation et qui
   s’occupera « dans un premier temps » de former les professeurs des
   lycées à ces nouvelles technologies. Cisco, acteur américain central de
   la « Safe City », et avec qui le gouvernement français avait déjà signé
   un partenariat important pour mener un projet de « Smart City » dans
   une ville française, se positionne dans un marché en plein essor. Il
   pourra pleinement tirer parti de cette occasion que lui donne la région
   de tester ses nouvelles technologies de surveillance dans nos
   établissements scolaires pour mieux la revendre plus tard, dans le
   cadre de marchés publics à vocation sécuritaire.

   Alors qu’il y a plus d’un mois, nous appelions déjà la CNIL à imposer
   un moratoire sur le développement de ces technologies, cette dernière
   semble s’en tenir à une posture attentiste. Nous appelons les syndicats
   de lycéens et d’enseignants ainsi que les parents d’élèves et toutes
   celles et ceux révulsés par ces évolutions à s’organiser pour les tenir
   en échec.

   References   [ + ]
   1. ↑ Il est ainsi seulement précisé dans les documents produits par la
   région, et cela sans aucune preuve ou réelle analyse, que « les
   nombreux incidents et agressions constatés aussi bien dans l’enceinte
   du lycée qu’à ses abords, ainsi que le contexte sécuritaire existant
   depuis les attentats terroristes de 2016, conduisent également à tenter
   de limiter les temps d’attente et les attroupements à l’extérieur des
   établissements aux moments de forte affluence (rentrées matinales
   notamment) » ou que « ce dispositif constitue une réponse au
   différentiel croissant constaté entre les exigences de sécurisation des
   entrées dans les établissements et les moyens humains disponibles dans
   les lycées, dans le cadre des plans successifs de réduction des
   effectifs de la fonction publique. Il apporte une assistance aux
   personnels du lycée, qui peuvent ainsi mieux se concentrer sur les cas
   nécessitant une intervention humaine, et reporter leur vigilance sur
   les multiples situations menaçant la sécurité, en augmentant la
   présence humaine dans les lieux de vie de l’établissement. »
   2. ↑ Le courrier de la région précise à ce titre que « Les personnes
   volontaires (ou leur représentant légal pour les mineurs) doivent
   signer préalablement un formulaire de recueil de consentement
   expliquant la finalité de l’expérimentation, la durée de conservation
   des donnée ainsi que la manière d’exercer les droits Informatique et
   Libertés »

   Posted in Surveillance
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires La Quadrature du Net » [Framablog] FLOK Society en
   Équateur : et si cela changeait véritablement la donne ? Flux des
   commentaires [Libération] Le contrôle d’Internet, un poison pour notre
   société [PCINpact] Philippe Aigrain condamne l’extension rampante du
   CSA sur le Net alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

[Framablog] FLOK Society en Équateur : et si cela changeait véritablement la
donne ?

   Posted on16 avril 201416 avril 2014

   [19699.jpg]

   Il a été dit dans un article précédent qu’il suffit qu’un pays change
   ses règles du jeu pour que cela impacte tous les autres. Ce pays sera
   peut-être l’Équateur et son ambitieux projet FLOK Society. […]

   FLOK est l’acronyme de Free/Libre Open Knowledge Society, la société
   pour la connaissance libre et ouverte. […] Parmi les actions prévues,
   il y a la mise en place d’un réseau mondial de chercheurs sur la
   transition, emmené par Michel Bauwens dont le point d’orgue devrait
   être une grande conférence internationale organisée sous peu (Jérémie
   Zimmerman et Bernard Stiegler sont par exemple dans la boucle, parmi
   les Français). […]

   Nous avons voulu en savoir plus en traduisant cette interview de
   quelques-uns des ses acteurs. […]

   http://www.framablog.org/index.php/post/2014/04/04/flok-society

   Posted in Revue de presse
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires La Quadrature du Net » Derrière les assistants vocaux, des
   humains vous entendent Flux des commentaires [FranceInter] Données
   personnelles : Gare au Gafam [LeMonde] Etats-Unis : le Sénat vote pour
   le maintien de la neutralité du Net alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

Derrière les assistants vocaux, des humains vous entendent

   Posted on18 mai 201813 novembre 2018

   Cette semaine, nous sommes allés à la rencontre de Julie, qui a
   travaillé pour une entreprise chargée d’ « améliorer » le
   fonctionnement de Cortana, l’assistant vocal de Microsoft, en écoutant
   une à une diverses paroles captées par la machine (volontairement ou
   non).

   Nous partageons ici son témoignage édifiant, en vidéo ainsi qu’à
   l’écrit (en fin d’article).

   Comme nous le rappelle Antonio Casilli ci-dessous, ce récit souligne
   exactement les pratiques très « humaines » que l’on retrouve en masse
   sous les miroirs trompeurs d’une soi-disant « intelligence
   artificielle ».

   Contre l’emprise des GAFAM sur nos vies, signez les plaintes
   collectives sur gafam.laquadrature.net

   IFRAME:
   https://video.lqdn.fr/videos/embed/9772f4a0-c025-4238-bfff-2ca473eceb54

Les humains derrière Cortana, par Antonio Casilli

   Antonio Casilli, membre de La Quadrature du Net, est maître de
   conférences en Digital Humanities à Telecom ParisTech et chercheur
   associé en sociologie au Centre Edgar-Morin, Ecole des Hautes Etudes en
   Sciences Sociales, Paris. Voir son site.

   Qui écoute vos conversations quand vous utilisez un assistant vocal
   comme Cortana ? Qui regarde vos requêtes quand vous utilisez un moteur
   de recherche comme Bing ? « Personne », vous assurent les concepteurs
   de ces dispositifs, « ce sont des machines ». La réalité est toute
   autre, comme l’atteste ce témoignage : une jeune femme qui, sans
   contrat de travail et sans aucun accord de confidentialité, a
   retranscrit des milliers de conversations privées, recherches
   d’information, noms et coordonnées personnelles de personnes utilisant
   des produits Microsoft.

   Son métier ? Dresseuse d’IA.

   Malgré les allégations de leurs producteurs, les assistants virtuels
   qui équipent les enceintes connectées trônant dans nos salles à manger
   ou qui se nichent jusque dans nos poches, installés sur nos
   smartphones, ne naissent pas intelligents. Ils doivent apprendre à
   interpréter les requêtes et les habitudes de leurs utilisateurs.

   Cet apprentissage est aidé par des êtres humains, qui vérifient la
   pertinence des réponses des assistants virtuels aux questions de leurs
   propriétaires. Mais plus souvent encore, ces êtres humains
   « entraînent » les dispositifs, en leurs fournissant des données déjà
   préparées, des requêtes avec des réponses toutes faites (ex. « Quelle
   est la météo aujourd’hui ? » : « Il fait 23 degrés » ou « Il pleut »),
   des phrases auxquelles ils fournissent des interprétations (ex. savoir
   dans quel contexte « la flotte » signifie « un ensemble de navires » ou
   « la pluie »).

   Ces dresseurs d’intelligences artificielles sont parfois des
   télétravailleurs payés à l’heure par des entreprises spécialisées. Dans
   d’autres cas, ils sont des « travailleurs à la pièce » recrutés sur des
   services web que l’on appelle des plateformes de micro-travail.

   Celle de Microsoft s’appelle UHRS et propose des rémunérations de 3, 2,
   voire même 1 centime de dollar par micro-tâche (retranscrire un mot,
   labelliser une image…). Parfois les personnes qui trient vos requêtes,
   regardent vos photos, écoutent vos propos sont situés dans votre pays,
   voire dans votre ville (peut-être vos voisins d’en bas ?). D’autres
   fois, ils sont des travailleurs précaires de pays francophones, comme
   la Tunisie, le Maroc ou Madagascar (qui s’est dernièrement imposé comme
   « leader français de l’intelligence artificielle »).

   Les logiciels à activation vocale tels Cortana, Siri ou Alexa sont des
   agents conversationnels qui possèdent une forte composante de travail
   non-artificiel. Cette implication humaine introduit des risques
   sociétaux spécifiques. La confidentialité des données personnelles
   utilisées pour entraîner les solutions intelligentes est à risque. Ces
   IA présupposent le transfert de quantités importantes de données à
   caractère personnel et existent dans une zone grise légale et éthique.

   Dans la mesure où les usagers des services numériques ignorent la
   présence d’êtres humains dans les coulisses de l’IA, ils sous-estiment
   les risques qui pèsent sur leur vie privée. Il est urgent de
   répertorier les atteintes à la privacy et à la confidentialité
   associées à cette forme de « digital labor », afin d’en estimer la
   portée pour informer, sensibiliser, et mieux protéger les personnes les
   plus exposées.

Témoignage complet de Julie

   J’ai travaillé comme transcripteuse (‘transcriber’) pour améliorer la
   qualité de la version française de Cortana, « votre assistante
   personnelle virtuelle » proposée par Microsoft. Je travaillais en
   télétravail pour une entreprise chinoise qui avait Microsoft pour
   client. J’ai commencé en Avril 2017 et arrêté en Décembre 2017.

   J’ai pu constater directement le type de données que Microsoft collecte
   via son petit monstre Cortana, car les données audio qu’elle collectait
   passaient entre nos mains (et nos oreilles !) pour analyse et
   correction.

   Microsoft, voulant améliorer les capacités de compréhension de Cortana,
   collectait les données des utilisateurs ‘consentants’. Donc, quand ces
   utilisateurs s’adressaient à Cortana, celle-ci collectait, enregistrait
   ce qu’ils disaient. Ensuite, Microsoft récupérait tout ça, envoyait une
   partie des enregistrements à la compagnie pour laquelle je travaillais,
   et celle-ci mettait le tout sur notre plate-forme de télétravail.

   Les transcripteurs se connectaient, et écoutaient un par un les
   enregistrements. Les pistes étaient généralement très courtes, entre 3
   et 15 secondes en moyenne (mais pouvaient parfois durer plusieurs
   minutes). En fonction des projets sur lesquels on travaillait, on
   devait réaliser entre 120 et 170 transcriptions/heure. Plusieurs
   milliers de pistes étaient déposées quotidiennement sur notre
   plate-forme.

   On écoutait l’enregistrement audio, ensuite un texte s’affichait, nous
   montrant ce que Cortana avait compris et retranscrit. Notre travail
   était de vérifier si elle avait bien compris – si ce n’était pas le
   cas, on devait corriger le texte, la moindre faute de compréhension, de
   conjugaison ou d’orthographe. Une autre partie du travail consistait à
   ajouter des tags dans le texte signalant les événements sonores qui
   pourraient expliquer pourquoi Cortana avait mal compris ceci ou mieux
   compris cela.

   Je n’ai pas le détail de la suite du processus, mais j’imagine
   qu’ensuite, les données que nous corrigions étaient envoyées à une
   équipe de techniciens, programmeurs et autres génies de l’informatique
   qui s’occupaient de faire comprendre à Cortana comment ne pas répéter
   les mêmes erreurs.

     Je me demandais à chaque fois si ces gens avaient conscience qu’une
     personne extérieure allaient entendre leurs petits délires sexuels

   Les données qu’on écoutait allaient d’Utilisateur A qui dit simplement
   « Hey Cortana, quelle sera la météo demain? » à Utilisateur B qui
   demande en chuchotant à Cortana de lui trouver des vidéos porno de
   telle ou telle catégorie…

   Il y avait leurs recherches internet, leurs interactions directes avec
   Cortana (« Hey Cortana, raconte-moi une blague« , « imite la poule »,
   « est-ce que tu m’aimes? », « est-ce que tu ressens la douleur? »…).
   Les utilisateurs peuvent aussi dicter du texte : messages, documents
   texte (résumés de cours, comptes-rendus professionnels…), adresses GPS,
   courriers administratifs (avec par exemple leur numéro de sécurité
   sociale), etc. ; nous avions accès à tout ça.

   Elle peut être connectée à des consoles Xbox, on avait donc aussi des
   enregistrements provenant de ce service-là. Il y avait notamment des
   morceaux de communication en ligne (principalement d’ados et d’enfants)
   qui discutent sur les jeux en réseaux.

   On avait également de nombreux extraits de conversations en ligne,
   sûrement sur Skype, provenant de personnes qui utilisaient un service
   de traduction instantanée (Microsoft Translator mais peut-être aussi
   Skype Translator, je ne suis pas certaine).

   Nous n’avions jamais l’intégralité des conversations évidemment, elles
   étaient découpées en petites pistes ; cependant on pouvait tomber sur
   plusieurs morceaux d’une même conversation dans une même série de
   transcriptions (c’était suffisant pour dresser un profil basique de
   l’utilisateur ou de son humeur du moment par exemple).

   On avait des conversations diverses, vraiment toutes sortes de choses,
   notamment souvent les séances sexcams de certains utilisateurs qui
   avaient besoin d’un service de traduction pour se faire comprendre, et
   dans ces cas-là les transcriptions étaient très explicites (parfois
   amusantes, parfois glauques). Je me demandais à chaque fois si ces gens
   avaient conscience qu’une personne extérieure allaient entendre leurs
   petits délires sexuels. Cortana ne fait pas le tri…

   Enfin, il y avait beaucoup d’enregistrements involontaires, où des
   personnes discutent entre elles (dans leur voiture, à la maison, avec
   leurs enfants sur le chemin de l’école…) tandis que Cortana est dans
   les parages (tablette, téléphone portable, ordinateur, etc.) et s’est
   déclenchée de manière non-sollicitée et a tout enregistré.

   (D’ailleurs, on avait aussi beaucoup d’utilisateurs qui insultaient
   tout simplement Cortana, car elle s’était déclenchée de façon
   non-sollicitée, ou avait mal compris une requête… Vous n’imaginez pas
   le nombre de fois où j’ai entendu « Sale pute Cortana ! » )

   On avait ainsi accès à énormément de données personnelles, que ce soit
   des bribes de conversations privées en ligne ou bien hors ligne.

     N’importe qui pouvait être engagé

   Pour pouvoir être embauché (ils recrutaient en grand nombre), il
   fallait s’inscrire sur le site de l’entreprise, postuler puis suivre
   une formation en ligne conclue par un examen final. Si on avait un
   pourcentage de réussite satisfaisant, on était engagé. Auquel cas, le
   manager nous faisait créer un compte sur le site internet de
   télétravail (une plate-forme externe, utilisée par plusieurs compagnies
   comme celle qui m’avait engagée), et le travail commençait.

   Il n’y avait pas besoin d’envoyer son CV, ni aucun entretien individuel
   avec un responsable ou un manager (ni par téléphone, ni par Skype, ni
   e-mail, rien). N’importe qui pouvait être engagé et avoir accès aux
   enregistrements du moment qu’ils en avaient les compétences techniques,
   que l’examen final avait été réussi. Pourtant, nous avions accès à des
   informations sensibles et personnelles.

   Beaucoup de personnes ignorent ou oublient que les données collectées
   par Cortana (et autres outils du genre) ne sont pas uniquement traitées
   par des robots, mais bien aussi par des êtres-humains.

   En m’inscrivant sur le site de l’entreprise, j’ai accepté ses
   conditions d’utilisations en cochant machinalement des petites cases,
   celles-ci parlaient d’une multitudes de choses, mais à ce que je me
   souviens il n’y avait pas d’emphase spéciale sur le respect de la vie
   privée des utilisateurs de nos clients. Et à aucun moment j’ai signé de
   ma main un contrat de confidentialité.

   Ils m’ont pourtant bien demandé de signer et renvoyer un document
   relatif aux taxes et impôts ; ils auraient pu en faire autant pour le
   respect de la confidentialité.

   Et sur plus d’une cinquantaine de pages d’instructions détaillées sur
   comment traiter les transcriptions, pas une seule ligne ne mentionnait
   le respect de la vie privée des utilisateurs. Pas un seul des nombreux
   e-mails du manager que nous recevions chaque semaine, rien n’a jamais
   été dédié au respect de la vie privée (en ligne et hors ligne) des
   utilisateurs.

   Et ce dont je parle ici ne concerne pas uniquement les utilisateurs
   français de Cortana, il y avait des équipes de transcripteurs pour une
   multitudes de langues (anglais, portugais, espagnol, etc.). On avait le
   même manager et les mêmes instructions générales.

   En théorie, les données étaient anonymes pour les transcripteurs,
   c’est-à-dire que nous n’avions jamais les identifiants des utilisateurs
   que nous écoutions, et les pistes étaient généralement distribuées de
   façon aléatoire et désordonnée, en plus d’être parfois découpées.
   Cependant, inévitablement il arrivait que les utilisateurs révèlent un
   numéro de téléphone, une adresse, des coordonnées, date de naissance,
   numéros importants, événements auxquels ils allaient se rendre, etc.

   Certaines voix se reconnaissent facilement, et bien que les pistes
   étaient aléatoires et dans le désordre, mises bout à bout elles
   auraient dans quelques cas pu suffire à un transcripteur déterminé pour
   identifier un utilisateur. De plus, on travaillait tous depuis nos
   propres ordinateurs, il était donc facile de récupérer les
   enregistrements qu’on traitait si on le voulait.

   Selon moi, ce n’était pas bien sécurisé, surtout quand on considère le
   fait qu’on avait aussi beaucoup d’enregistrements provenant d’enfants.
   Mais il faut comprendre que ce genre de traitement de données est de
   toute façon impossible à sécuriser entièrement (encore moins quand on
   sous-traite), car des données récoltées massivement ne peuvent pas être
   triées parfaitement, des informations sensibles passeront toujours.

     Beaucoup d’utilisateurs se sentent dépassés par tout ça, et les
     GAFAM savent exactement comment en tirer parti

   Enfin, j’aimerais parler du fait qu’il me semble évident que la plupart
   des logiciels de reconnaissance vocale et assistants virtuels doivent
   se construire comme Cortana, donc il est important que les gens
   mesurent ce qu’utiliser de tels logiciels implique (ce que j’ai décrit
   n’est assurément pas juste typique à Microsoft).

   Avec l’affluence des nouveaux  »assistants personnels virtuels », le
   champs des possibles pour la collecte de données s’est développé de
   manière fulgurante.
   Le modèle de Microsoft (et les autres GAFAM) n’est pas basé sur le
   respect de la vie privée et la non-intrusion, c’est le contraire.

   Les outils comme Cortana sont hautement intrusifs et ont accès à une
   liste impressionnante de données personnelles, qu’ils exploitent et
   développent simultanément.

   La collecte de données qu’ils peuvent permettre peut être utilisée à
   votre insu, détournée, utilisée contre votre gré, tombée entre de
   mauvaises mains, être exploitée à des fins auxquelles vous n’avez
   jamais consciemment donné votre accord…

   Personnaliser les paramètres de confidentialité de services de ce genre
   requiert parfois des compétences en informatique qui dépassent
   l’utilisateur amateur, et des écrans de fumée font oublier que vous
   sacrifiez et marchandez votre vie privée à l’aide de formules comme
   « personnalisation du contenu », « optimisation des résultats »,
   « amélioration de votre expérience et de nos services ».

   Beaucoup d’utilisateurs se sentent dépassés par tout ça, et les GAFAM
   savent exactement comment en tirer parti.
   Merci beaucoup à Julie pour son témoignage !

   Contre l’emprise des GAFAM sur nos vies, signez les plaintes
   collectives sur gafam.laquadrature.net

   Posted in Données personnelles
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires alternate alternate alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

   logo logo

La Quadrature du Net ouvre la bataille contre la Technopolice

   Posted on16 septembre 201916 septembre 2019

   Appel à participation : rejoignez la campagne Technopolice !
   En lien avec la conférence de presse tenue à Nice ce matin avec la
   Ligue des Droits de l’Homme, la FCPE et CGT-Educ, La Quadrature du Net
   lance un…

Surveillance publicitaire : compte-rendu du référé contre la CNIL

   Posted on21 août 2019

   Le 14 août se tenait au Conseil d’État l’audience de référé de notre
   affaire contre la CNIL. Nous demandions à ce que soit suspendue dans
   l’urgence son autorisation donnée aux sites Web de nous tracer…

Recours contre le renseignement français : audience devant la Cour de Justice
de l’Union européenne le 9 septembre 2019

   Posted on12 août 2019

   Le 9 septembre prochain, se tiendra à Luxembourg, devant la Grande
   chambre de la Cour de Justice de l’Union européenne, l’audience sur la
   loi Renseignement française et l’obligation de conservation généralisée
   des données de connexion.…

Surveillance publicitaire : La Quadrature du Net attaque la CNIL en référé

   Posted on2 août 20197 août 2019

   Ce lundi 29 juillet, comme annoncé, nous avons déposé devant le Conseil
   d’État, avec l’association Caliopen, un recours contre la décision de
   la CNIL d’autoriser la « poursuite de la navigation » comme mode
   d’expression du consentement…

De la modération

   Posted on22 juillet 201924 juillet 2019

   Une tribune d’Okhin
   Le sujet fleurit dans tous les espaces. Les GAFAM demandent à cor et à
   cri des règles de modération qu’ils pourraient appliquer, se contentant
   pour le moment de leurs « règles communautaires » qui ne…

La Quadrature du Net attaque l’application ALICEM, contre la généralisation
de la reconnaissance faciale

   Posted on17 juillet 2019

   Lundi dernier, La Quadrature du Net a déposé un recours devant le
   Conseil d’État pour demander l’annulation du décret autorisant la
   création de l’application mobile intitulée « ALICEM », pour
   « Authentification en ligne certifiée sur mobile ». En…

L’Assemblée nationale adopte et aggrave la loi « haine »

   Posted on9 juillet 20199 juillet 2019

   L’Assemblée Nationale a adopté aujourd’hui la loi « haine », débattue
   mercredi et jeudi derniers. Le texte n’a pas été amélioré mais au
   contraire aggravé, avec des ajouts absurdes et dangereux.
   Sur les dangers de ce texte…

Résumé de la loi « haine » avant le vote de demain

   Posted on2 juillet 2019

   L’Assemblée nationale discutera demain et après-demain la proposition
   de loi « contre la haine en ligne ». Débattue en procédure accélérée,
   il pourrait s’agir du dernier passage de ce texte devant les députés.
   Leur dernier occasion pour…

La loi « haine » va transformer Internet en télévision

   Posted on1 juillet 20191 juillet 2019

   La proposition de loi portée par Laetitia Avia prétend vouloir faire du
   CSA « l’accompagnateur des plateformes » dans la lutte « contre la
   haine en ligne ». En réalité, la loi va beaucoup plus loin. Comme cela
   est…

La CNIL veut autoriser les sites Internet à nous tracer sans notre
consentement

   Posted on28 juin 201918 juillet 2019

   Mise à jour du 18 juillet 2019 : la CNIL vient de confirmer son
   intention dans un communiqué. Nous l’attaquerons dans l’été.
   Hier, Mme Marie-Laure Denis, présidente de la CNIL, a expliqué en
   commission de l’Assemblée nationale…

Navigation des articles

   Page 1 Page 2 … Page 48 Next Page
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires La Quadrature du Net » Reconnaissance faciale : un recours
   pour faire barrage à la surveillance biométrique Flux des commentaires
   [ActualitedesLuttes] Vidéosurveillance et menace des libertés sur les
   réseaux sociaux Le Conseil constitutionnel censure l’accès des douanes
   aux données de connexion alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

Reconnaissance faciale : un recours pour faire barrage à la surveillance
biométrique

   Posted on19 février 201919 février 2019

   Quatre organisations – La Quadrature du Net, la Ligue des droits de
   l’Homme, CGT Educ’Action des Alpes-Maritimes et la Fédération des
   Conseils de Parents d’Élèves des écoles publiques des Alpes-Maritimes –
   viennent de déposer un recours devant le tribunal administratif de
   Marseille pour demander l’annulation de la délibération du conseil
   régional autorisant la mise en œuvre d’une expérimentation de
   reconnaissance faciale dans deux lycées de la région.

   Ce recours intervient alors que la polémique enfle après que la mairie
   de Nice a annoncé expérimenter la reconnaissance faciale dans le cadre
   du carnaval.

   Le 14 décembre 2018, le conseil régional de la région Sud (ex-PACA) a
   voté une délibération visant à faire installer à l’entrée de deux
   lycées de la région — le lycée des Eucalyptus à Nice et le lycée Ampère
   à Marseille — un dispositif de reconnaissance faciale. Ce dispositif
   expérimental, installé et financé par la société états-unienne Cisco, a
   vocation, comme l’a précisé M. Christian Estrosi lors du vote au
   Conseil régional, à être étendu à l’ensemble des établissements
   scolaires de la région.

   Devant l’inaction de la CNIL et alors que cette expérimentation prépare
   la banalisation de la surveillance par reconnaissance faciale, les
   quatre organisations requérantes ont décidé de saisir le tribunal
   administratif de Marseille pour demander l’annulation de cette
   délibération.

   Les arguments juridiques soulevés s’appuient essentiellement sur le
   règlement général sur la protection des données (RGPD) : la
   délibération, votée alors qu’aucune analyse d’impact n’avait été
   réalisée, permet en effet la mise en œuvre d’un traitement de données
   biométriques qui est notamment manifestement disproportionné par
   rapport à l’objectif poursuivi (apporter « une assistance aux agents en
   charge du contrôle d’accès au lycée et de l’accueil ») et qui n’est
   fondée sur aucune règle juridique adaptée, claire et intelligible,
   contrairement à ce qu’impose la Convention européenne des droits de
   l’Homme en matière de droit à la vie privée. La délibération autorisant
   cette expérimentation est donc illégale et doit être annulée.

   Le recours est accessible ici.

   Pour Martin Drago, juriste à La Quadrature du Net :

   « Cette expérimentation vise à accoutumer les élèves à une surveillance
   biométrique. Cela participe à la banalisation de ce type de
   technologies, alors que des projets sécuritaires de vidéosurveillance
   dopées à la reconnaissance faciale pullulent désormais sur le
   territoire français. On trouve malheureusement bien peu de monde pour y
   faire barrage, que ce soit à la CNIL ou au niveau des élus locaux et à
   ce stade, les juges apparaissent comme l’ultime rempart
   institutionnel. »

   Pour Maryse Artiguelong, vice-présidente de la Ligue des droits de
   l’Homme :

   « Pour la Ligue des droits de l’Homme (LDH) cette expérimentation de
   reconnaissance faciale, qui permet l’identification à l’aide de données
   biométriques particulièrement sensibles – elles permettent notamment de
   déterminer l’origine ethnique, qui plus est sur des élèves en majorité
   mineurs – est particulièrement inquiétante. »

   Pour Laure Guérard-Boushor, de la CGT Educ’Action des Alpes-Maritimes :

   « Répression contre les lycéen.ne.s, mise en place de mesures pour
   restreindre le droit de manifester et maintenant mise en place d’un
   système de reconnaissance faciale à l’entrée de l’établissement les EK
   à Nice et Ampère à Marseille; l’escalade est toujours plus importante.
   Nous condamnons ces projets qui remettent en cause tous les principes
   de la liberté qu’elle soit individuelle ou collective ; qui laissent la
   porte ouverte à toutes les dérives, toutes les discriminations. Nous
   demandons à ce que l’argent dont notre école publique a besoin ne soit
   pas gaspillé dans des mesures dont on connaît l’inutilité et la
   nocivité. »

   Pour Laëtitia Siccardi, présidente de la Fédération des Conseils de
   Parents d’Élèves des écoles publiques des Alpes-Maritimes :

   « Cette expérimentation est une dérive sécuritaire de plus, et nous
   sommes extrêmement attentifs à ce que les droits fondamentaux des
   lycéens soient respectés. De plus, il s’agit une fois encore d’un
   investissement financier considérable au service d’une mesure à
   l’efficacité douteuse.»

   Posted in Surveillance
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires La Quadrature du Net » Reconnaissance faciale au lycée :
   l’expérimentation avant la généralisation Flux des commentaires Résumé
   de nos arguments contre la surveillance française devant les juges
   européens Première sanction contre Google suite à nos plaintes
   collectives alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

Reconnaissance faciale au lycée : l’expérimentation avant la généralisation

   Posted on19 décembre 201820 décembre 2018

   Le 14 décembre dernier, le Conseil Régional de PACA a voté une mesure
   visant à faire installer, à partir de 2019, des dispositifs de
   reconnaissance faciale à l’entrée de deux lycées de Nice et de
   Marseille. Dès le mois d’octobre, La Quadrature du Net avait demandé à
   la CNIL la communication des documents en sa possession sur ce dossier,
   cette dernière ayant été consultée par la région pour la mise en place
   de ces dispositifs. L’analyse de ces documents, ainsi que les
   précisions apportées par Christian Estrosi, confirment l’impuissance de
   la CNIL à enrayer la banalisation d’une technologie particulièrement
   liberticide et qui vise ici à s’étendre à l’ensemble des établissements
   scolaires de la région.

   Mise à jour (20 décembre 2018) – nous publions les documents suivants :
     * La réponse de la CNIL à notre demande
     * La lettre de Renaud Muselier présentant le projet à la CNIL
     * L’exposé détaillé du projet par la région
     * La demande de renseignements complémentaires par la CNIL à la
       région et la réponse de cette dernière

   De quoi s’agit-il ? En octobre 2017, Renaud Muselier, président de la
   région PACA, demande les conseils de la CNIL pour la mise en place dans
   deux lycées de Nice et de Marseille de dispositifs de « portiques
   virtuels » associant « des moyens classiques d’identification (…) à un
   dispositif biométrique utilisant des technologies de comparaison
   faciale, seuls à même d’après nos premières investigations, d’apporter
   une solution fiable et rapide dans un contexte de contrôle d’accès
   portant sur un nombre potentiellement élevé de personnes ». Cette
   nouvelle étape est la suite logique de sa politique sécuritaire ayant
   conduit, entre 2016 et 2017, à ce que plus de 1 300 caméras de
   vidéosurveillance soient installées dans l’ensemble des lycées de la
   région. La technologisation à outrance est également présentée par la
   région comme une réponse au contexte d’austérité budgétaire :

     Ce dispositif constitue une réponse au différentiel croissant
     constaté entre les exigences de sécurisation des entrées dans les
     établissements et les moyens humains disponibles dans les lycées,
     dans le cadre des plans successifs de réduction des effectifs dans
     la fonction publique.

   La région PACA présente ainsi à la CNIL son projet visant à
   « sanctuariser » les entrées et les sorties dans les établissements
   secondaires. Il s’agit non seulement de reconnaissance faciale mais
   également d’un dispositif de « suivi de trajectoire » de certains des
   visiteurs : un logiciel installé couplé à une caméra permet de détecter
   des points de comparaison faciale déterminés par un algorithme et de le
   comparer avec ceux stockés dans une base de données. Un écran mis à la
   disposition des agents de contrôle permet alors de visualiser trois
   types de profils : « vert » pour les personnes autorisées à pénétrer
   dans l’enceinte du lycée, « jaune » pour les personnes non identifiées
   et invitées à se présenter à l’accueil et « rouge » pour les personnes
   non identifiées et qui ne se sont pas dirigées dès leur entrée vers
   l’accueil.

   Il est par ailleurs précisé qu’il s’agit pour l’instant d’une
   « expérimentation limitée dans le temps » et fondée sur le consentement
   explicite de volontaires au sein des établissements visés.

La CNIL impuissante face au développement de la reconnaissance faciale

   Alors qu’elle avait appelé en septembre 2018 à un débat urgent sur ces
   nouveaux usages des caméras vidéo et qu’elle souligne elle-même les
   risques considérables d’atteinte aux libertés individuelles que cette
   technologie entraîne, la CNIL n’a opéré ici qu’un suivi très souple –
   voire accommodant – du projet.

   Soulignons d’abord que, depuis l’entrée en vigueur du RGPD en mai 2018,
   les responsables de traitement de données personnelles n’ont en
   principe plus à réaliser de formalités auprès de la CNIL avant la mise
   en œuvre du traitement, tel qu’obtenir son autorisation dans certains
   cas. Le contrôle de l’autorité ne se fait qu’a posteriori, conformément
   au principe de responsabilisation des acteurs prévu dans le règlement.
   Tout au plus certains traitements, et c’est le cas pour la
   reconnaissance faciale, doivent-ils faire l’objet d’une analyse
   d’impact. Le consentement des utilisateurs est désormais censé fournir
   une base légale suffisante pour le déploiement de ces systèmes qui font
   pourtant entrer la surveillance dans une nouvelle ère. En supprimant le
   pouvoir d’autorisation de la CNIL s’agissant de ce type de dispositifs,
   le RGPD marque donc un recul pour les libertés.

   Selon les documents qui nous ont été communiqués, la CNIL s’est donc
   contentée de demander des précisions complémentaires à la Région sur le
   dispositif envisagé et, sur certains points, de fournir des
   recommandations. C’est d’ailleurs suite à l’une de ces recommandations
   que la Région a décidé que le stockage des données biométriques ne se
   ferait pas sur une base de données mais sur un support individuel, sous
   le contrôle exclusif de la personne (en l’espèce, un badge) (comme
   c’est le cas pour ce qui existe déjà dans plusieurs aéroports où la
   photographie n’est stockée que dans le microprocesseur du passeport
   biométrique).

   Ainsi, et contrairement à ce qui a été annoncé par une partie de la
   presse et par Christian Estrosi lui-même, la CNIL n’a pas donné son
   « feu vert » à ce dispositif mais a simplement accompagné la région
   dans sa mise en place.

   Pourtant, en laissant se développer ce type de technologies à des buts
   sécuritaires, sans qu’il ne soit apporté à un seul moment la preuve de
   la pertinence d’un tel dispositif par rapport au système existant,^1Il
   est ainsi seulement précisé dans les documents produits par la région,
   et cela sans aucune preuve ou réelle analyse, que « les nombreux
   incidents et agressions constatés aussi bien dans l’enceinte du lycée
   qu’à ses abords, ainsi que le contexte sécuritaire existant depuis les
   attentats terroristes de 2016, conduisent également à tenter de limiter
   les temps d’attente et les attroupements à l’extérieur des
   établissements aux moments de forte affluence (rentrées matinales
   notamment) » ou que « ce dispositif constitue une réponse au
   différentiel croissant constaté entre les exigences de sécurisation des
   entrées dans les établissements et les moyens humains disponibles dans
   les lycées, dans le cadre des plans successifs de réduction des
   effectifs de la fonction publique. Il apporte une assistance aux
   personnels du lycée, qui peuvent ainsi mieux se concentrer sur les cas
   nécessitant une intervention humaine, et reporter leur vigilance sur
   les multiples situations menaçant la sécurité, en augmentant la
   présence humaine dans les lieux de vie de l’établissement. » sans même
   une réelle réflexion sur la nature du consentement que peuvent donner
   des mineurs à l’égard d’une expérimentation au sein de leur lycée,^2Le
   courrier de la région précise à ce titre que « Les personnes
   volontaires (ou leur représentant légal pour les mineurs) doivent
   signer préalablement un formulaire de recueil de consentement
   expliquant la finalité de l’expérimentation, la durée de conservation
   des donnée ainsi que la manière d’exercer les droits Informatique et
   Libertés » la CNIL participe à la banalisation de ces technologies.
   Elle devient l’alibi au développement d’une surveillance généralisée
   qui sera au cœur des « Safe City » qui commencent à essaimer sur le
   territoire.

Un dispositif qui a vocation à s’étendre à toute la région

   Car, sous le qualificatif faussement tranquillisant d’
   « expérimentation » mis en exergue par Renaud Muselier et Christian
   Estrosi, ces derniers souhaitent en réalité, comme ils l’ont eux-mêmes
   énoncé lors de l’assemblée plénière du Conseil Régional, étendre ce
   dispositif de reconnaissance faciale à l’ensemble des lycées de la
   région :

     Avec ces deux expériences, une fois que nous l’aurons démontré, nous
     irons très vite sur la généralisation, à partir du réseau de
     vidéosurveillance déjà existant, sur lequel il ne nous restera plus
     qu’à mettre le logiciel qui correspond à l’usage de la
     reconnaissance faciale par rapport aux caméras déjà installées dans
     nos établissements scolaires.

   L’expérimentation des lycées de Nice et de Marseille s’inscrit donc en
   réalité parfaitement dans les divers projets que La Quadrature du Net
   dénonce depuis près d’un an, et qui sont d’ailleurs particulièrement
   avancés dans ces deux villes : « Observatoire Big Data de la
   tranquillité publique » à Marseille, « Safe City » à Nice… Cette
   actualité apparaît alors comme une
   nouvelle briqueau développement, toujours plus rapide et incontrôlable,
   de ces nouvelles technologies de surveillance (« Big Data », caméras
   « intelligentes », reconnaissance faciale…) au profit des municipalités
   et de leurs polices.

   Un tel projet profitera par ailleurs pleinement à son maître d’œuvre,
   la société CISCO, qui finance entièrement cette expérimentation et qui
   s’occupera « dans un premier temps » de former les professeurs des
   lycées à ces nouvelles technologies. Cisco, acteur américain central de
   la « Safe City », et avec qui le gouvernement français avait déjà signé
   un partenariat important pour mener un projet de « Smart City » dans
   une ville française, se positionne dans un marché en plein essor. Il
   pourra pleinement tirer parti de cette occasion que lui donne la région
   de tester ses nouvelles technologies de surveillance dans nos
   établissements scolaires pour mieux la revendre plus tard, dans le
   cadre de marchés publics à vocation sécuritaire.

   Alors qu’il y a plus d’un mois, nous appelions déjà la CNIL à imposer
   un moratoire sur le développement de ces technologies, cette dernière
   semble s’en tenir à une posture attentiste. Nous appelons les syndicats
   de lycéens et d’enseignants ainsi que les parents d’élèves et toutes
   celles et ceux révulsés par ces évolutions à s’organiser pour les tenir
   en échec.

   References   [ + ]
   1. ↑ Il est ainsi seulement précisé dans les documents produits par la
   région, et cela sans aucune preuve ou réelle analyse, que « les
   nombreux incidents et agressions constatés aussi bien dans l’enceinte
   du lycée qu’à ses abords, ainsi que le contexte sécuritaire existant
   depuis les attentats terroristes de 2016, conduisent également à tenter
   de limiter les temps d’attente et les attroupements à l’extérieur des
   établissements aux moments de forte affluence (rentrées matinales
   notamment) » ou que « ce dispositif constitue une réponse au
   différentiel croissant constaté entre les exigences de sécurisation des
   entrées dans les établissements et les moyens humains disponibles dans
   les lycées, dans le cadre des plans successifs de réduction des
   effectifs de la fonction publique. Il apporte une assistance aux
   personnels du lycée, qui peuvent ainsi mieux se concentrer sur les cas
   nécessitant une intervention humaine, et reporter leur vigilance sur
   les multiples situations menaçant la sécurité, en augmentant la
   présence humaine dans les lieux de vie de l’établissement. »
   2. ↑ Le courrier de la région précise à ce titre que « Les personnes
   volontaires (ou leur représentant légal pour les mineurs) doivent
   signer préalablement un formulaire de recueil de consentement
   expliquant la finalité de l’expérimentation, la durée de conservation
   des donnée ainsi que la manière d’exercer les droits Informatique et
   Libertés »

   Posted in Surveillance
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires La Quadrature du Net » [Framablog] FLOK Society en
   Équateur : et si cela changeait véritablement la donne ? Flux des
   commentaires [Libération] Le contrôle d’Internet, un poison pour notre
   société [PCINpact] Philippe Aigrain condamne l’extension rampante du
   CSA sur le Net alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

[Framablog] FLOK Society en Équateur : et si cela changeait véritablement la
donne ?

   Posted on16 avril 201416 avril 2014

   [19699.jpg]

   Il a été dit dans un article précédent qu’il suffit qu’un pays change
   ses règles du jeu pour que cela impacte tous les autres. Ce pays sera
   peut-être l’Équateur et son ambitieux projet FLOK Society. […]

   FLOK est l’acronyme de Free/Libre Open Knowledge Society, la société
   pour la connaissance libre et ouverte. […] Parmi les actions prévues,
   il y a la mise en place d’un réseau mondial de chercheurs sur la
   transition, emmené par Michel Bauwens dont le point d’orgue devrait
   être une grande conférence internationale organisée sous peu (Jérémie
   Zimmerman et Bernard Stiegler sont par exemple dans la boucle, parmi
   les Français). […]

   Nous avons voulu en savoir plus en traduisant cette interview de
   quelques-uns des ses acteurs. […]

   http://www.framablog.org/index.php/post/2014/04/04/flok-society

   Posted in Revue de presse
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires La Quadrature du Net » Derrière les assistants vocaux, des
   humains vous entendent Flux des commentaires [FranceInter] Données
   personnelles : Gare au Gafam [LeMonde] Etats-Unis : le Sénat vote pour
   le maintien de la neutralité du Net alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

Derrière les assistants vocaux, des humains vous entendent

   Posted on18 mai 201813 novembre 2018

   Cette semaine, nous sommes allés à la rencontre de Julie, qui a
   travaillé pour une entreprise chargée d’ « améliorer » le
   fonctionnement de Cortana, l’assistant vocal de Microsoft, en écoutant
   une à une diverses paroles captées par la machine (volontairement ou
   non).

   Nous partageons ici son témoignage édifiant, en vidéo ainsi qu’à
   l’écrit (en fin d’article).

   Comme nous le rappelle Antonio Casilli ci-dessous, ce récit souligne
   exactement les pratiques très « humaines » que l’on retrouve en masse
   sous les miroirs trompeurs d’une soi-disant « intelligence
   artificielle ».

   Contre l’emprise des GAFAM sur nos vies, signez les plaintes
   collectives sur gafam.laquadrature.net

   IFRAME:
   https://video.lqdn.fr/videos/embed/9772f4a0-c025-4238-bfff-2ca473eceb54

Les humains derrière Cortana, par Antonio Casilli

   Antonio Casilli, membre de La Quadrature du Net, est maître de
   conférences en Digital Humanities à Telecom ParisTech et chercheur
   associé en sociologie au Centre Edgar-Morin, Ecole des Hautes Etudes en
   Sciences Sociales, Paris. Voir son site.

   Qui écoute vos conversations quand vous utilisez un assistant vocal
   comme Cortana ? Qui regarde vos requêtes quand vous utilisez un moteur
   de recherche comme Bing ? « Personne », vous assurent les concepteurs
   de ces dispositifs, « ce sont des machines ». La réalité est toute
   autre, comme l’atteste ce témoignage : une jeune femme qui, sans
   contrat de travail et sans aucun accord de confidentialité, a
   retranscrit des milliers de conversations privées, recherches
   d’information, noms et coordonnées personnelles de personnes utilisant
   des produits Microsoft.

   Son métier ? Dresseuse d’IA.

   Malgré les allégations de leurs producteurs, les assistants virtuels
   qui équipent les enceintes connectées trônant dans nos salles à manger
   ou qui se nichent jusque dans nos poches, installés sur nos
   smartphones, ne naissent pas intelligents. Ils doivent apprendre à
   interpréter les requêtes et les habitudes de leurs utilisateurs.

   Cet apprentissage est aidé par des êtres humains, qui vérifient la
   pertinence des réponses des assistants virtuels aux questions de leurs
   propriétaires. Mais plus souvent encore, ces êtres humains
   « entraînent » les dispositifs, en leurs fournissant des données déjà
   préparées, des requêtes avec des réponses toutes faites (ex. « Quelle
   est la météo aujourd’hui ? » : « Il fait 23 degrés » ou « Il pleut »),
   des phrases auxquelles ils fournissent des interprétations (ex. savoir
   dans quel contexte « la flotte » signifie « un ensemble de navires » ou
   « la pluie »).

   Ces dresseurs d’intelligences artificielles sont parfois des
   télétravailleurs payés à l’heure par des entreprises spécialisées. Dans
   d’autres cas, ils sont des « travailleurs à la pièce » recrutés sur des
   services web que l’on appelle des plateformes de micro-travail.

   Celle de Microsoft s’appelle UHRS et propose des rémunérations de 3, 2,
   voire même 1 centime de dollar par micro-tâche (retranscrire un mot,
   labelliser une image…). Parfois les personnes qui trient vos requêtes,
   regardent vos photos, écoutent vos propos sont situés dans votre pays,
   voire dans votre ville (peut-être vos voisins d’en bas ?). D’autres
   fois, ils sont des travailleurs précaires de pays francophones, comme
   la Tunisie, le Maroc ou Madagascar (qui s’est dernièrement imposé comme
   « leader français de l’intelligence artificielle »).

   Les logiciels à activation vocale tels Cortana, Siri ou Alexa sont des
   agents conversationnels qui possèdent une forte composante de travail
   non-artificiel. Cette implication humaine introduit des risques
   sociétaux spécifiques. La confidentialité des données personnelles
   utilisées pour entraîner les solutions intelligentes est à risque. Ces
   IA présupposent le transfert de quantités importantes de données à
   caractère personnel et existent dans une zone grise légale et éthique.

   Dans la mesure où les usagers des services numériques ignorent la
   présence d’êtres humains dans les coulisses de l’IA, ils sous-estiment
   les risques qui pèsent sur leur vie privée. Il est urgent de
   répertorier les atteintes à la privacy et à la confidentialité
   associées à cette forme de « digital labor », afin d’en estimer la
   portée pour informer, sensibiliser, et mieux protéger les personnes les
   plus exposées.

Témoignage complet de Julie

   J’ai travaillé comme transcripteuse (‘transcriber’) pour améliorer la
   qualité de la version française de Cortana, « votre assistante
   personnelle virtuelle » proposée par Microsoft. Je travaillais en
   télétravail pour une entreprise chinoise qui avait Microsoft pour
   client. J’ai commencé en Avril 2017 et arrêté en Décembre 2017.

   J’ai pu constater directement le type de données que Microsoft collecte
   via son petit monstre Cortana, car les données audio qu’elle collectait
   passaient entre nos mains (et nos oreilles !) pour analyse et
   correction.

   Microsoft, voulant améliorer les capacités de compréhension de Cortana,
   collectait les données des utilisateurs ‘consentants’. Donc, quand ces
   utilisateurs s’adressaient à Cortana, celle-ci collectait, enregistrait
   ce qu’ils disaient. Ensuite, Microsoft récupérait tout ça, envoyait une
   partie des enregistrements à la compagnie pour laquelle je travaillais,
   et celle-ci mettait le tout sur notre plate-forme de télétravail.

   Les transcripteurs se connectaient, et écoutaient un par un les
   enregistrements. Les pistes étaient généralement très courtes, entre 3
   et 15 secondes en moyenne (mais pouvaient parfois durer plusieurs
   minutes). En fonction des projets sur lesquels on travaillait, on
   devait réaliser entre 120 et 170 transcriptions/heure. Plusieurs
   milliers de pistes étaient déposées quotidiennement sur notre
   plate-forme.

   On écoutait l’enregistrement audio, ensuite un texte s’affichait, nous
   montrant ce que Cortana avait compris et retranscrit. Notre travail
   était de vérifier si elle avait bien compris – si ce n’était pas le
   cas, on devait corriger le texte, la moindre faute de compréhension, de
   conjugaison ou d’orthographe. Une autre partie du travail consistait à
   ajouter des tags dans le texte signalant les événements sonores qui
   pourraient expliquer pourquoi Cortana avait mal compris ceci ou mieux
   compris cela.

   Je n’ai pas le détail de la suite du processus, mais j’imagine
   qu’ensuite, les données que nous corrigions étaient envoyées à une
   équipe de techniciens, programmeurs et autres génies de l’informatique
   qui s’occupaient de faire comprendre à Cortana comment ne pas répéter
   les mêmes erreurs.

     Je me demandais à chaque fois si ces gens avaient conscience qu’une
     personne extérieure allaient entendre leurs petits délires sexuels

   Les données qu’on écoutait allaient d’Utilisateur A qui dit simplement
   « Hey Cortana, quelle sera la météo demain? » à Utilisateur B qui
   demande en chuchotant à Cortana de lui trouver des vidéos porno de
   telle ou telle catégorie…

   Il y avait leurs recherches internet, leurs interactions directes avec
   Cortana (« Hey Cortana, raconte-moi une blague« , « imite la poule »,
   « est-ce que tu m’aimes? », « est-ce que tu ressens la douleur? »…).
   Les utilisateurs peuvent aussi dicter du texte : messages, documents
   texte (résumés de cours, comptes-rendus professionnels…), adresses GPS,
   courriers administratifs (avec par exemple leur numéro de sécurité
   sociale), etc. ; nous avions accès à tout ça.

   Elle peut être connectée à des consoles Xbox, on avait donc aussi des
   enregistrements provenant de ce service-là. Il y avait notamment des
   morceaux de communication en ligne (principalement d’ados et d’enfants)
   qui discutent sur les jeux en réseaux.

   On avait également de nombreux extraits de conversations en ligne,
   sûrement sur Skype, provenant de personnes qui utilisaient un service
   de traduction instantanée (Microsoft Translator mais peut-être aussi
   Skype Translator, je ne suis pas certaine).

   Nous n’avions jamais l’intégralité des conversations évidemment, elles
   étaient découpées en petites pistes ; cependant on pouvait tomber sur
   plusieurs morceaux d’une même conversation dans une même série de
   transcriptions (c’était suffisant pour dresser un profil basique de
   l’utilisateur ou de son humeur du moment par exemple).

   On avait des conversations diverses, vraiment toutes sortes de choses,
   notamment souvent les séances sexcams de certains utilisateurs qui
   avaient besoin d’un service de traduction pour se faire comprendre, et
   dans ces cas-là les transcriptions étaient très explicites (parfois
   amusantes, parfois glauques). Je me demandais à chaque fois si ces gens
   avaient conscience qu’une personne extérieure allaient entendre leurs
   petits délires sexuels. Cortana ne fait pas le tri…

   Enfin, il y avait beaucoup d’enregistrements involontaires, où des
   personnes discutent entre elles (dans leur voiture, à la maison, avec
   leurs enfants sur le chemin de l’école…) tandis que Cortana est dans
   les parages (tablette, téléphone portable, ordinateur, etc.) et s’est
   déclenchée de manière non-sollicitée et a tout enregistré.

   (D’ailleurs, on avait aussi beaucoup d’utilisateurs qui insultaient
   tout simplement Cortana, car elle s’était déclenchée de façon
   non-sollicitée, ou avait mal compris une requête… Vous n’imaginez pas
   le nombre de fois où j’ai entendu « Sale pute Cortana ! » )

   On avait ainsi accès à énormément de données personnelles, que ce soit
   des bribes de conversations privées en ligne ou bien hors ligne.

     N’importe qui pouvait être engagé

   Pour pouvoir être embauché (ils recrutaient en grand nombre), il
   fallait s’inscrire sur le site de l’entreprise, postuler puis suivre
   une formation en ligne conclue par un examen final. Si on avait un
   pourcentage de réussite satisfaisant, on était engagé. Auquel cas, le
   manager nous faisait créer un compte sur le site internet de
   télétravail (une plate-forme externe, utilisée par plusieurs compagnies
   comme celle qui m’avait engagée), et le travail commençait.

   Il n’y avait pas besoin d’envoyer son CV, ni aucun entretien individuel
   avec un responsable ou un manager (ni par téléphone, ni par Skype, ni
   e-mail, rien). N’importe qui pouvait être engagé et avoir accès aux
   enregistrements du moment qu’ils en avaient les compétences techniques,
   que l’examen final avait été réussi. Pourtant, nous avions accès à des
   informations sensibles et personnelles.

   Beaucoup de personnes ignorent ou oublient que les données collectées
   par Cortana (et autres outils du genre) ne sont pas uniquement traitées
   par des robots, mais bien aussi par des êtres-humains.

   En m’inscrivant sur le site de l’entreprise, j’ai accepté ses
   conditions d’utilisations en cochant machinalement des petites cases,
   celles-ci parlaient d’une multitudes de choses, mais à ce que je me
   souviens il n’y avait pas d’emphase spéciale sur le respect de la vie
   privée des utilisateurs de nos clients. Et à aucun moment j’ai signé de
   ma main un contrat de confidentialité.

   Ils m’ont pourtant bien demandé de signer et renvoyer un document
   relatif aux taxes et impôts ; ils auraient pu en faire autant pour le
   respect de la confidentialité.

   Et sur plus d’une cinquantaine de pages d’instructions détaillées sur
   comment traiter les transcriptions, pas une seule ligne ne mentionnait
   le respect de la vie privée des utilisateurs. Pas un seul des nombreux
   e-mails du manager que nous recevions chaque semaine, rien n’a jamais
   été dédié au respect de la vie privée (en ligne et hors ligne) des
   utilisateurs.

   Et ce dont je parle ici ne concerne pas uniquement les utilisateurs
   français de Cortana, il y avait des équipes de transcripteurs pour une
   multitudes de langues (anglais, portugais, espagnol, etc.). On avait le
   même manager et les mêmes instructions générales.

   En théorie, les données étaient anonymes pour les transcripteurs,
   c’est-à-dire que nous n’avions jamais les identifiants des utilisateurs
   que nous écoutions, et les pistes étaient généralement distribuées de
   façon aléatoire et désordonnée, en plus d’être parfois découpées.
   Cependant, inévitablement il arrivait que les utilisateurs révèlent un
   numéro de téléphone, une adresse, des coordonnées, date de naissance,
   numéros importants, événements auxquels ils allaient se rendre, etc.

   Certaines voix se reconnaissent facilement, et bien que les pistes
   étaient aléatoires et dans le désordre, mises bout à bout elles
   auraient dans quelques cas pu suffire à un transcripteur déterminé pour
   identifier un utilisateur. De plus, on travaillait tous depuis nos
   propres ordinateurs, il était donc facile de récupérer les
   enregistrements qu’on traitait si on le voulait.

   Selon moi, ce n’était pas bien sécurisé, surtout quand on considère le
   fait qu’on avait aussi beaucoup d’enregistrements provenant d’enfants.
   Mais il faut comprendre que ce genre de traitement de données est de
   toute façon impossible à sécuriser entièrement (encore moins quand on
   sous-traite), car des données récoltées massivement ne peuvent pas être
   triées parfaitement, des informations sensibles passeront toujours.

     Beaucoup d’utilisateurs se sentent dépassés par tout ça, et les
     GAFAM savent exactement comment en tirer parti

   Enfin, j’aimerais parler du fait qu’il me semble évident que la plupart
   des logiciels de reconnaissance vocale et assistants virtuels doivent
   se construire comme Cortana, donc il est important que les gens
   mesurent ce qu’utiliser de tels logiciels implique (ce que j’ai décrit
   n’est assurément pas juste typique à Microsoft).

   Avec l’affluence des nouveaux  »assistants personnels virtuels », le
   champs des possibles pour la collecte de données s’est développé de
   manière fulgurante.
   Le modèle de Microsoft (et les autres GAFAM) n’est pas basé sur le
   respect de la vie privée et la non-intrusion, c’est le contraire.

   Les outils comme Cortana sont hautement intrusifs et ont accès à une
   liste impressionnante de données personnelles, qu’ils exploitent et
   développent simultanément.

   La collecte de données qu’ils peuvent permettre peut être utilisée à
   votre insu, détournée, utilisée contre votre gré, tombée entre de
   mauvaises mains, être exploitée à des fins auxquelles vous n’avez
   jamais consciemment donné votre accord…

   Personnaliser les paramètres de confidentialité de services de ce genre
   requiert parfois des compétences en informatique qui dépassent
   l’utilisateur amateur, et des écrans de fumée font oublier que vous
   sacrifiez et marchandez votre vie privée à l’aide de formules comme
   « personnalisation du contenu », « optimisation des résultats »,
   « amélioration de votre expérience et de nos services ».

   Beaucoup d’utilisateurs se sentent dépassés par tout ça, et les GAFAM
   savent exactement comment en tirer parti.
   Merci beaucoup à Julie pour son témoignage !

   Contre l’emprise des GAFAM sur nos vies, signez les plaintes
   collectives sur gafam.laquadrature.net

   Posted in Données personnelles
   #La Quadrature du Net » Flux La Quadrature du Net » Flux des
   commentaires alternate alternate alternate alternate

   [ ]
     * Accueil
     * Données persoDonnées personnelles
     * Censure
     * Surveillance
     * Télécoms
     * Donner
     * Nous
     * Agenda
     * FR
          + EN
          + ES
          + DE
     * ____________________ (BUTTON) Search

À venir
   27 septembre à 15h50 Le quatrième âge de l'informatique sociale avec
       Philippe Aigrain et Félix Tréguer Centre Internet et Société 59-61,
       rue Pouchet 75017 Paris/cis.cnrs.fr
   3 octobre à 19h00 Conférence "Safe Cities" Maison du Protestantisme ,
       3, rue Claude Brousson à NÎMES avec Félix Tréguer
   9 octobre à 18h15 Conférence « Faut-il protéger sa vie privée sur
       internet ? » Bruxelles

   logo logo

La Quadrature du Net ouvre la bataille contre la Technopolice

   Posted on16 septembre 201916 septembre 2019

   Appel à participation : rejoignez la campagne Technopolice !
   En lien avec la conférence de presse tenue à Nice ce matin avec la
   Ligue des Droits de l’Homme, la FCPE et CGT-Educ, La Quadrature du Net
   lance un…

Surveillance publicitaire : compte-rendu du référé contre la CNIL

   Posted on21 août 2019

   Le 14 août se tenait au Conseil d’État l’audience de référé de notre
   affaire contre la CNIL. Nous demandions à ce que soit suspendue dans
   l’urgence son autorisation donnée aux sites Web de nous tracer…

Recours contre le renseignement français : audience devant la Cour de Justice
de l’Union européenne le 9 septembre 2019

   Posted on12 août 2019

   Le 9 septembre prochain, se tiendra à Luxembourg, devant la Grande
   chambre de la Cour de Justice de l’Union européenne, l’audience sur la
   loi Renseignement française et l’obligation de conservation généralisée
   des données de connexion.…

Surveillance publicitaire : La Quadrature du Net attaque la CNIL en référé

   Posted on2 août 20197 août 2019

   Ce lundi 29 juillet, comme annoncé, nous avons déposé devant le Conseil
   d’État, avec l’association Caliopen, un recours contre la décision de
   la CNIL d’autoriser la « poursuite de la navigation » comme mode
   d’expression du consentement…

De la modération

   Posted on22 juillet 201924 juillet 2019

   Une tribune d’Okhin
   Le sujet fleurit dans tous les espaces. Les GAFAM demandent à cor et à
   cri des règles de modération qu’ils pourraient appliquer, se contentant
   pour le moment de leurs « règles communautaires » qui ne…

La Quadrature du Net attaque l’application ALICEM, contre la généralisation
de la reconnaissance faciale

   Posted on17 juillet 2019

   Lundi dernier, La Quadrature du Net a déposé un recours devant le
   Conseil d’État pour demander l’annulation du décret autorisant la
   création de l’application mobile intitulée « ALICEM », pour
   « Authentification en ligne certifiée sur mobile ». En…

L’Assemblée nationale adopte et aggrave la loi « haine »

   Posted on9 juillet 20199 juillet 2019

   L’Assemblée Nationale a adopté aujourd’hui la loi « haine », débattue
   mercredi et jeudi derniers. Le texte n’a pas été amélioré mais au
   contraire aggravé, avec des ajouts absurdes et dangereux.
   Sur les dangers de ce texte…

Résumé de la loi « haine » avant le vote de demain

   Posted on2 juillet 2019

   L’Assemblée nationale discutera demain et après-demain la proposition
   de loi « contre la haine en ligne ». Débattue en procédure accélérée,
   il pourrait s’agir du dernier passage de ce texte devant les députés.
   Leur dernier occasion pour…

La loi « haine » va transformer Internet en télévision

   Posted on1 juillet 20191 juillet 2019

   La proposition de loi portée par Laetitia Avia prétend vouloir faire du
   CSA « l’accompagnateur des plateformes » dans la lutte « contre la
   haine en ligne ». En réalité, la loi va beaucoup plus loin. Comme cela
   est…

La CNIL veut autoriser les sites Internet à nous tracer sans notre
consentement

   Posted on28 juin 201918 juillet 2019

   Mise à jour du 18 juillet 2019 : la CNIL vient de confirmer son
   intention dans un communiqué. Nous l’attaquerons dans l’été.
   Hier, Mme Marie-Laure Denis, présidente de la CNIL, a expliqué en
   commission de l’Assemblée nationale…

Navigation des articles

   Page 1 Page 2 … Page 48 Next Page
